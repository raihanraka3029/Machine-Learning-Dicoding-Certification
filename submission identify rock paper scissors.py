# -*- coding: utf-8 -*-
"""Copy of Submission Machine learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hnQgZCr6wLXSQoto5XpNvV89TWSqx4y4

NAMA: MUHAMMAD RAIHAN RAKASIWI
EMAIL: rehan.rakasiwi@gmail.com
KELAS: Machine learning untuk pemula
"""

#IMPORT LIBRARY YANG DIBUTUHKAN DAN CEK VERSI TENSORFLOW >2.0
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
import zipfile
import shutil
print(tf.__version__)

!wget --no-check-certificate / https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip


# Penggunaan Callback mencegah overfitting dan menghentikan training setelah akurasi terpenuhi
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.93):
      print("\nAkurasi di atas 93%, hentikan training!")
      self.model.stop_training = True

callbacks = myCallback()


#CHECK DAN CLEANING DIRECTORY
path = '/tmp/rockpaperscissors/'

isFile = os.path.isfile(path)
print(isFile)

if isFile == True:
    shutil.rmtree('/tmp/rockpaperscissors/', ignore_errors=False, onerror=None)
else:
   print('skipped')


#MELAKUKAN EKSTRAKSI FILE ZIP (karena zipfile dan os telah di import maka tidak perlu mengimport lagi seperti di modul)
local_zip = 'rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

base_dir = '/tmp/rockpaperscissors'
train_dir = os.path.join (base_dir, 'rps-cv-images')

os.listdir(base_dir)

os.listdir(train_dir)

#PENGOLAHAN DATA
train_datagen = ImageDataGenerator(rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.4,# Data validation 40%
    fill_mode='nearest')

test_datagen = ImageDataGenerator(rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.4, # Data validation 40%
    fill_mode='nearest')

#DATA PROCESSING DAN SPLITTING DATA KE TRAINING DAN VALIDATION

train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(150, 150),  # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        batch_size=4,# karena ini merupakan masalah klasifikasi 3 kelas maka menggunakan class_mode = 'categorical'
        class_mode='categorical',
        subset ='training')


validation_generator = test_datagen.flow_from_directory(
        train_dir,
        target_size=(150, 150), # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        batch_size=4
        , # karena ini merupakan masalah klasifikasi 3 kelas maka menggunakan class_mode = 'categorical'
        class_mode='categorical',
        subset = 'validation')

#MEMBUAT ARSITEKTUR CNN
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
     tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

#MEMANGGIL FUNGSI COMPILE
model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

#PROSES PELATIHAN
hhistory = model.fit(
    train_generator,
    steps_per_epoch = 25,
    epochs = 25,
    validation_data = validation_generator,
    validation_steps = 25,
    verbose =2,
      callbacks=[callbacks]
)

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

uploaded = files.upload()

for fn in uploaded.keys():

  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150, 150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)

  #Changing result into human language
  print(fn)
  if classes[0,0]!=0:
    print('paper')
  elif classes[0,1]!=0:
    print('rock')
  else:
    print('scissors')